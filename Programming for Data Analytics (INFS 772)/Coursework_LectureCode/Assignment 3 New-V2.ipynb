{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFS 772 Programming for Data Analytics Spring 2019\n",
    "## Assignment 3: Visualization with seaborn and K-nearest neighbors with scikit-learn (total 20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Due Friday, March 29, 11:59pm\n",
    "### The coding requirements are for 14 points.\n",
    "### All easily avoidable runtime errors would lead to additional point reductions.\n",
    "### Parameter Tuning with Cross Validation (5 extra credits)\n",
    "\n",
    "#### Hints: \n",
    "- There is a youtube video (link is on D2L) for the scikit-learn part\n",
    "- Visualization of the iris dataset with seaborn is also on D2L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Review of the iris dataset\n",
    "2. Visualizing the iris dataset with Matplotlib and Seaborn\n",
    "3. K-nearest neighbors (KNN) classification\n",
    "4. Review of supervised learning\n",
    "5. Benefits and drawbacks of scikit-learn\n",
    "6. Requirements for working with data in scikit-learn\n",
    "7. scikit-learn's 4-step modeling pattern\n",
    "8. Tuning a KNN model\n",
    "9. Comparing KNN with other models\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Learn how the modeling process works\n",
    "2. Learn how scikit-learn works\n",
    "3. Learn how KNN works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the iris dataset\n",
    "### You are required to download the dataset as a flat file directly from the Internet. (1 point)\n",
    "### Rename the colums (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in/Generic Imports\n",
    "import os\n",
    "import sys\n",
    "#\n",
    "\n",
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn.plots\n",
    "import seaborn as sns\n",
    "#\n",
    "\n",
    "# Modules\n",
    "from io import StringIO\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "#\n",
    "\n",
    "\n",
    "#Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the iris data into a DataFrame\n",
    "# from http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "# name the columns as 'sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'\n",
    "\n",
    "iris = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "- **150 observations** (n=150): each observation is one iris flower\n",
    "- **4 features** (p=4): sepal length, sepal width, petal length, and petal width\n",
    "- **Response**: iris species\n",
    "- **Classification problem** since response is categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human learning on the iris dataset\n",
    "\n",
    "How did we (as humans) predict the species of an iris?\n",
    "\n",
    "1. We observed that the different species had (somewhat) dissimilar measurements.\n",
    "2. We focused on features that seemed to correlate with the response.\n",
    "3. We created a set of rules (using those features) to predict the species of an unknown iris.\n",
    "\n",
    "We assumed that if an **unknown iris** has measurements similar to **previous irises**, then its species is most likely the same as those previous irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# increase default figure and font sizes for easier viewing\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# create a custom colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each iris species to a number\n",
    "iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot of PETAL LENGTH versus PETAL WIDTH and color by SPECIES\n",
    "iris.plot(kind='scatter', x='petal_length', y='petal_width', c='species_num', colormap=cmap_bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a scatter plot of SEPAL LENGTH versus SEPAL WIDTH and color by SPECIES\n",
    "iris.plot(kind='scatter', x='sepal_length', y='sepal_width', c='species_num', colormap=cmap_bold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the above with seaborn (1 point)\n",
    "#### We'll use seaborn's FacetGrid to color the scatterplot by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kdeplot (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A seaborn plot useful for looking at univariate relations is the kdeplot,\n",
    "# which creates and visualizes a kernel density estimate of the underlying feature\n",
    "\n",
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair plots with seaborn (1 point)\n",
    "#### Make sure species are in different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another multivariate visualization technique pandas has is parallel_coordinates (1 point)\n",
    "#### Parallel coordinates plots each feature on a separate column & then draws lines connecting the features for each data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors (KNN) classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the data that are \"nearest\" to the measurements of the unknown iris.\n",
    "    - Euclidian distance is often used as the distance metric, but other metrics are allowed.\n",
    "3. Use the most popular response value from the K \"nearest neighbors\" as the predicted response value for the unknown iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map for iris (K=1)\n",
    "\n",
    "![1NN classification map](images/iris_01nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map for iris (K=5)\n",
    "\n",
    "![5NN classification map](images/iris_05nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map for iris (K=15)\n",
    "\n",
    "![15NN classification map](images/iris_15nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map for iris (K=50)\n",
    "\n",
    "![50NN classification map](images/iris_50nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What's the \"best\" value for K in this case?\n",
    "\n",
    "**Answer:** The value which produces the most accurate predictions on **unseen data**. We want to create a model that generalizes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of supervised learning\n",
    "\n",
    "![Supervised learning diagram](images/supervised_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits and drawbacks of scikit-learn\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- Consistent interface to machine learning models\n",
    "- Provides many tuning parameters but with sensible defaults\n",
    "- Exceptional documentation\n",
    "- Rich set of functionality for companion tasks\n",
    "- Active community for development and support\n",
    "\n",
    "**Potential drawbacks:**\n",
    "\n",
    "- Harder (than R) to get started with machine learning\n",
    "- Less emphasis (than R) on model interpretability\n",
    "\n",
    "Ben Lorica: [Six reasons why I recommend scikit-learn](http://radar.oreilly.com/2013/12/six-reasons-why-i-recommend-scikit-learn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for working with data in scikit-learn\n",
    "\n",
    "1. Features and response should be **separate objects**\n",
    "2. Features and response should be entirely **numeric**\n",
    "3. Features and response should be **NumPy arrays** (or easily converted to NumPy arrays)\n",
    "4. Features and response should have **specific shapes** (outlined below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store feature matrix in \"X\"\n",
    "feature_cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "X = iris[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative ways to create \"X\"\n",
    "X = iris.drop(['species', 'species_num'], axis=1)\n",
    "X = iris.loc[:, 'sepal_length':'petal_width']\n",
    "X = iris.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store response vector in \"y\"\n",
    "y = iris.species_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check X's type\n",
    "print(type(X))\n",
    "print(type(X.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check y's type\n",
    "print(type(y))\n",
    "print(type(y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check X's shape (n = number of observations, p = number of features)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check y's shape (single dimension with length n)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn's 4-step modeling pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the class you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** \"Instantiate\" the \"estimator\" (1 point)\n",
    "\n",
    "- \"Estimator\" is scikit-learn's term for \"model\"\n",
    "- \"Instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an instance of a KNeighborsClassifier object\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created an object that \"knows\" how to do K-nearest neighbors classification, and is just waiting for data\n",
    "- Name of the object does not matter\n",
    "- Can specify tuning parameters (aka \"hyperparameters\") during this step\n",
    "- All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Fit the model with data (aka \"model training\") (1 point)\n",
    "\n",
    "- Model is \"learning\" the relationship between X and y in our \"training data\"\n",
    "- Process through which learning occurs varies by model\n",
    "- Occurs in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with X and y\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once a model has been fit with data, it's called a \"fitted model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4:** Predict the response for a new observation (1 point)\n",
    "\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a NumPy array, and we keep track of what the numbers \"mean\"\n",
    "- Can predict for multiple observations at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[3, 5, 4, 2], [5, 4, 3, 2]]\n",
    "# predict the class of X_new\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning a KNN model (1 point each part, total 3 points here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model (using the value K=5)\n",
    "\n",
    "# your code here\n",
    "\n",
    "# fit the model with data\n",
    "# your code here\n",
    "\n",
    "# predict the response for new observations\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which model produced the correct predictions for the two unknown irises?\n",
    "\n",
    "**Answer:** We don't know, because these are **out-of-sample observations**, meaning that we don't know the true response values. Our goal with supervised learning is to build models that generalize to out-of-sample data. However, we can't truly measure how well our models will perform on out-of-sample data.\n",
    "\n",
    "**Question:** Does that mean that we have to guess how well our models are likely to do?\n",
    "\n",
    "**Answer:** Thankfully, no. In the next class, we'll discuss **model evaluation procedures**, which allow us to use our existing labeled data to estimate how well our models are likely to perform on out-of-sample data. These procedures will help us to tune our models and choose between different types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predicted probabilities of class membership (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predicted probabilities of class membership\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Confusion Matrix (1 point)\n",
    "\n",
    "Definition: number of samples of class $i$ predicted as class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning with Cross Validation (5 extra credits)\n",
    "In this section, we’ll explore a method that can be used to tune the hyperparameter K.\n",
    "Using the test set for hyperparameter tuning can lead to overfitting.\n",
    "An alternative and smarter approach involves estimating the test error rate by holding out a subset of the training set from the fitting process. This subset, called the validation set, can be used to select the appropriate level of flexibility of our algorithm! There are different validation approaches that are used in practice, and we will be exploring one of the more popular ones called k-fold cross validation.\n",
    "We’re going to perform a 10-fold cross validation on our dataset using a generated list of odd K’s ranging from 1 to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Your codes below\n",
    "# creating odd list of K for KNN\n",
    "\n",
    "\n",
    "# subsetting just the odd ones\n",
    "\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "\n",
    "# print cv scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the optimal number of K? Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing KNN with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of KNN:**\n",
    "\n",
    "- Simple to understand and explain\n",
    "- Model training is fast\n",
    "- Can be used for classification and regression\n",
    "\n",
    "**Disadvantages of KNN:**\n",
    "\n",
    "- Must store all of the training data\n",
    "- Prediction phase can be slow when n is large\n",
    "- Sensitive to irrelevant features\n",
    "- Sensitive to the scale of the data\n",
    "- Accuracy is (generally) not competitive with the best supervised learning methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
