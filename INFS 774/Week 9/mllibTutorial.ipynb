{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Library (MLlib)\n",
    "MLlib is Sparkâ€™s machine learning (ML) library. Its goal is to make practical machine learning scalable and easy. At a high level, it provides tools such as:\n",
    "\n",
    "- ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering\n",
    "- Featurization: feature extraction, transformation, dimensionality reduction, and selection\n",
    "- Pipelines: tools for constructing, evaluating, and tuning ML Pipelines\n",
    "- Persistence: saving and load algorithms, models, and Pipelines\n",
    "- Utilities: linear algebra, statistics, data handling, etc.\n",
    "\n",
    "As of Spark 2.0, the RDD-based APIs in the spark.mllib package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the spark.ml package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example classification model\n",
    "The objective is to learn how to build a complete classification workflow from the beginning to the end.\n",
    "Problem Definition.  The problem we are going to solve is the infamous Titanic Survival Problem. We are asked to build a machine learning model that takes passenger information and predict whether he/she survived or not. The dataset contains 12 columns described as follows: \n",
    "![Titanic data description](titanic.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data = spark.read.csv('titanic.csv', inferSchema=True, header=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us filter out the unneeded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Survived=0, Pclass=3, Gender='male', Age=22.0, SibSp=1, Parch=0, Fare=7.25),\n",
       " Row(Survived=1, Pclass=1, Gender='female', Age=38.0, SibSp=1, Parch=0, Fare=71.2833),\n",
       " Row(Survived=1, Pclass=3, Gender='female', Age=26.0, SibSp=0, Parch=0, Fare=7.925)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.select(['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare'])\n",
    "data.printSchema()\n",
    "data.head(3) # this is an action. Head() returns a list of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------+------------------+------------------+-------------------+-----------------+\n",
      "|summary|           Survived|            Pclass|Gender|               Age|             SibSp|              Parch|             Fare|\n",
      "+-------+-------------------+------------------+------+------------------+------------------+-------------------+-----------------+\n",
      "|  count|                891|               891|   891|               714|               891|                891|              891|\n",
      "|   mean| 0.3838383838383838| 2.308641975308642|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824| 32.2042079685746|\n",
      "| stddev|0.48659245426485753|0.8360712409770491|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|49.69342859718089|\n",
      "|    min|                  0|                 1|female|              0.42|                 0|                  0|              0.0|\n",
      "|    max|                  1|                 3|  male|              80.0|                 8|                  6|         512.3292|\n",
      "+-------+-------------------+------------------+------+------------------+------------------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show() # show basic stats that is very useful for continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|Gender|count|\n",
      "+------+-----+\n",
      "|female|  314|\n",
      "|  male|  577|\n",
      "+------+-----+\n",
      "\n",
      "+----+-----+\n",
      "| Age|count|\n",
      "+----+-----+\n",
      "| 8.0|    4|\n",
      "|70.0|    2|\n",
      "| 7.0|    3|\n",
      "|20.5|    1|\n",
      "|49.0|    6|\n",
      "|29.0|   20|\n",
      "|40.5|    2|\n",
      "|64.0|    2|\n",
      "|47.0|    9|\n",
      "|42.0|   13|\n",
      "|24.5|    1|\n",
      "|44.0|    9|\n",
      "|35.0|   18|\n",
      "|null|  177|\n",
      "|62.0|    4|\n",
      "|18.0|   26|\n",
      "|80.0|    1|\n",
      "|34.5|    1|\n",
      "|39.0|   14|\n",
      "| 1.0|    7|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|SibSp|count|\n",
      "+-----+-----+\n",
      "|    1|  209|\n",
      "|    3|   16|\n",
      "|    5|    5|\n",
      "|    4|   18|\n",
      "|    8|    7|\n",
      "|    2|   28|\n",
      "|    0|  608|\n",
      "+-----+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|Parch|count|\n",
      "+-----+-----+\n",
      "|    1|  118|\n",
      "|    6|    1|\n",
      "|    3|    5|\n",
      "|    5|    5|\n",
      "|    4|    4|\n",
      "|    2|   80|\n",
      "|    0|  678|\n",
      "+-----+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|   Fare|count|\n",
      "+-------+-----+\n",
      "| 8.5167|    1|\n",
      "|   15.5|    8|\n",
      "| 133.65|    2|\n",
      "| 29.125|    5|\n",
      "|10.4625|    2|\n",
      "| 7.0458|    1|\n",
      "|  9.475|    1|\n",
      "|11.1333|    3|\n",
      "|    0.0|   15|\n",
      "| 7.7333|    4|\n",
      "|   73.5|    5|\n",
      "|77.2875|    2|\n",
      "|   15.9|    2|\n",
      "|   11.5|    4|\n",
      "| 8.6833|    1|\n",
      "|41.5792|    3|\n",
      "|    9.5|    9|\n",
      "| 8.4042|    1|\n",
      "|14.4542|    7|\n",
      "|14.4583|    3|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code to show value count of each variable. This is very useful for categorical variables. \n",
    "for column in data.columns:\n",
    "    data.groupBy(column).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If a continuous variable contains missing values, we do missing value imputation in two steps: 1) We add a missing value indicator; and 2) we replace missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|AgeMissing|count|\n",
      "+----------+-----+\n",
      "|         1|  177|\n",
      "|         0|  714|\n",
      "+----------+-----+\n",
      "\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|AgeMissing|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|         0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|         0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|         0|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|         0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|         0|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583|         1|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|         0|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|         0|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|         0|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|         0|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|         0|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|         0|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|         0|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|         0|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|         0|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|         0|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|         0|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|         1|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|         0|\n",
      "|       1|     3|female|null|    0|    0|  7.225|         1|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|AgeMissing|       AgeImputed|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|         0|             22.0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|         0|             38.0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|         0|             26.0|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|         0|             35.0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|         0|             35.0|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583|         1|29.69911764705882|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|         0|             54.0|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|         0|              2.0|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|         0|             27.0|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|         0|             14.0|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|         0|              4.0|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|         0|             58.0|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|         0|             20.0|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|         0|             39.0|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|         0|             14.0|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|         0|             55.0|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|         0|              2.0|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|         1|29.69911764705882|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|         0|             31.0|\n",
      "|       1|     3|female|null|    0|    0|  7.225|         1|29.69911764705882|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "data = data.withColumn('AgeMissing', f.when(f.isnull(data['age']), 1).otherwise(0))\n",
    "data.groupBy(\"AgeMissing\").count().show()\n",
    "data.show()\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(strategy='mean', inputCols=['Age'], outputCols=['AgeImputed'])\n",
    "imputer_model = imputer.fit(data)\n",
    "data = imputer_model.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variable encoding:\n",
    "We learned that machine learning algorithms cannot deal with categorical features. So, we need to index the Gender values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|AgeMissing|       AgeImputed|GenderIndexed|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|         0|             22.0|          0.0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|         0|             38.0|          1.0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|         0|             26.0|          1.0|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|         0|             35.0|          1.0|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|         0|             35.0|          0.0|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583|         1|29.69911764705882|          0.0|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|         0|             54.0|          0.0|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|         0|              2.0|          0.0|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|         0|             27.0|          1.0|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|         0|             14.0|          1.0|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|         0|              4.0|          1.0|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|         0|             58.0|          1.0|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|         0|             20.0|          0.0|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|         0|             39.0|          0.0|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|         0|             14.0|          1.0|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|         0|             55.0|          1.0|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|         0|              2.0|          0.0|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|         1|29.69911764705882|          0.0|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|         0|             31.0|          1.0|\n",
      "|       1|     3|female|null|    0|    0|  7.225|         1|29.69911764705882|          1.0|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "gender_indexer = StringIndexer(inputCol='Gender', outputCol='GenderIndexed')\n",
    "gender_indexer_model = gender_indexer.fit(data)\n",
    "data = gender_indexer_model.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You still need to deal with ordinal/nominal variables - You need to do dummy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+-------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|AgeMissing|       AgeImputed|GenderIndexed|    PclassVec|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+-------------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|         0|             22.0|          0.0|    (3,[],[])|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|         0|             38.0|          1.0|(3,[1],[1.0])|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|         0|             26.0|          1.0|    (3,[],[])|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|         0|             35.0|          1.0|(3,[1],[1.0])|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|         0|             35.0|          0.0|    (3,[],[])|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583|         1|29.69911764705882|          0.0|    (3,[],[])|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|         0|             54.0|          0.0|(3,[1],[1.0])|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|         0|              2.0|          0.0|    (3,[],[])|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|         0|             27.0|          1.0|    (3,[],[])|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|         0|             14.0|          1.0|(3,[2],[1.0])|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|         0|              4.0|          1.0|    (3,[],[])|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|         0|             58.0|          1.0|(3,[1],[1.0])|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|         0|             20.0|          0.0|    (3,[],[])|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|         0|             39.0|          0.0|    (3,[],[])|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|         0|             14.0|          1.0|    (3,[],[])|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|         0|             55.0|          1.0|(3,[2],[1.0])|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|         0|              2.0|          0.0|    (3,[],[])|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|         1|29.69911764705882|          0.0|(3,[2],[1.0])|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|         0|             31.0|          1.0|    (3,[],[])|\n",
      "|       1|     3|female|null|    0|    0|  7.225|         1|29.69911764705882|          1.0|    (3,[],[])|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"Pclass\"],\n",
    "                                 outputCols=[\"PclassVec\"])\n",
    "model = encoder.fit(data)\n",
    "data = model.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Features Vector\n",
    "MLlib expects data to be represented in two columns: a features vector and a label column. We have the label column ready (Survived), so let us prepare the features vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+-------------+--------------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|AgeMissing|       AgeImputed|GenderIndexed|    PclassVec|            features|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+-------------+--------------------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|         0|             22.0|          0.0|    (3,[],[])|(9,[0,2,4],[1.0,7...|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|         0|             38.0|          1.0|(3,[1],[1.0])|[1.0,0.0,71.2833,...|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|         0|             26.0|          1.0|    (3,[],[])|(9,[2,4,5],[7.925...|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|         0|             35.0|          1.0|(3,[1],[1.0])|[1.0,0.0,53.1,0.0...|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|         0|             35.0|          0.0|    (3,[],[])|(9,[2,4],[8.05,35...|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583|         1|29.69911764705882|          0.0|    (3,[],[])|(9,[2,3,4],[8.458...|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|         0|             54.0|          0.0|(3,[1],[1.0])|(9,[2,4,7],[51.86...|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|         0|              2.0|          0.0|    (3,[],[])|(9,[0,1,2,4],[3.0...|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|         0|             27.0|          1.0|    (3,[],[])|(9,[1,2,4,5],[2.0...|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|         0|             14.0|          1.0|(3,[2],[1.0])|[1.0,0.0,30.0708,...|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|         0|              4.0|          1.0|    (3,[],[])|[1.0,1.0,16.7,0.0...|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|         0|             58.0|          1.0|(3,[1],[1.0])|(9,[2,4,5,7],[26....|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|         0|             20.0|          0.0|    (3,[],[])|(9,[2,4],[8.05,20...|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|         0|             39.0|          0.0|    (3,[],[])|(9,[0,1,2,4],[1.0...|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|         0|             14.0|          1.0|    (3,[],[])|(9,[2,4,5],[7.854...|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|         0|             55.0|          1.0|(3,[2],[1.0])|(9,[2,4,5,8],[16....|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|         0|              2.0|          0.0|    (3,[],[])|(9,[0,1,2,4],[4.0...|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|         1|29.69911764705882|          0.0|(3,[2],[1.0])|(9,[2,3,4,8],[13....|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|         0|             31.0|          1.0|    (3,[],[])|(9,[0,2,4,5],[1.0...|\n",
      "|       1|     3|female|null|    0|    0|  7.225|         1|29.69911764705882|          1.0|    (3,[],[])|(9,[2,3,4,5],[7.2...|\n",
      "+--------+------+------+----+-----+-----+-------+----------+-----------------+-------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Survived=0, Pclass=3, Gender='male', Age=22.0, SibSp=1, Parch=0, Fare=7.25, AgeMissing=0, AgeImputed=22.0, GenderIndexed=0.0, PclassVec=SparseVector(3, {}), features=SparseVector(9, {0: 1.0, 2: 7.25, 4: 22.0})),\n",
       " Row(Survived=1, Pclass=1, Gender='female', Age=38.0, SibSp=1, Parch=0, Fare=71.2833, AgeMissing=0, AgeImputed=38.0, GenderIndexed=1.0, PclassVec=SparseVector(3, {1: 1.0}), features=DenseVector([1.0, 0.0, 71.2833, 0.0, 38.0, 1.0, 0.0, 1.0, 0.0])),\n",
       " Row(Survived=1, Pclass=3, Gender='female', Age=26.0, SibSp=0, Parch=0, Fare=7.925, AgeMissing=0, AgeImputed=26.0, GenderIndexed=1.0, PclassVec=SparseVector(3, {}), features=SparseVector(9, {2: 7.925, 4: 26.0, 5: 1.0})),\n",
       " Row(Survived=1, Pclass=1, Gender='female', Age=35.0, SibSp=1, Parch=0, Fare=53.1, AgeMissing=0, AgeImputed=35.0, GenderIndexed=1.0, PclassVec=SparseVector(3, {1: 1.0}), features=DenseVector([1.0, 0.0, 53.1, 0.0, 35.0, 1.0, 0.0, 1.0, 0.0])),\n",
       " Row(Survived=0, Pclass=3, Gender='male', Age=35.0, SibSp=0, Parch=0, Fare=8.05, AgeMissing=0, AgeImputed=35.0, GenderIndexed=0.0, PclassVec=SparseVector(3, {}), features=SparseVector(9, {2: 8.05, 4: 35.0}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['SibSp', 'Parch', 'Fare', 'AgeMissing', 'AgeImputed', 'GenderIndexed', 'PclassVec'], outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "data.show()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Training vs. test dataset partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use Randomforest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "algo = RandomForestClassifier(featuresCol='features', labelCol='Survived')\n",
    "model = algo.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+\n",
      "|Survived|prediction|         probability|\n",
      "+--------+----------+--------------------+\n",
      "|       0|       0.0|[0.84005078342312...|\n",
      "|       0|       0.0|[0.65774691756379...|\n",
      "|       0|       0.0|[0.65774691756379...|\n",
      "|       0|       0.0|[0.70034897625191...|\n",
      "|       0|       0.0|[0.70034897625191...|\n",
      "|       0|       0.0|[0.69932266046244...|\n",
      "|       0|       0.0|[0.61705243035456...|\n",
      "|       0|       0.0|[0.58924865072409...|\n",
      "|       0|       0.0|[0.79303504454620...|\n",
      "|       0|       0.0|[0.61363329549109...|\n",
      "|       0|       0.0|[0.67153759366521...|\n",
      "|       0|       0.0|[0.65853261591172...|\n",
      "|       0|       0.0|[0.65853261591172...|\n",
      "|       0|       0.0|[0.65736176948938...|\n",
      "|       0|       0.0|[0.70037620775897...|\n",
      "|       0|       0.0|[0.68212453041439...|\n",
      "|       0|       1.0|[0.26752852959931...|\n",
      "|       0|       0.0|[0.88108177084285...|\n",
      "|       0|       0.0|[0.82112991216259...|\n",
      "|       0|       0.0|[0.71016503428457...|\n",
      "+--------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make prediction using test data\n",
    "predictions = model.transform(test)\n",
    "predictions.select(['Survived','prediction', 'probability']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In MLlib the default metric used for evaluating classification models is area_under_roc (auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8863015138772078"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using spark ml to do model evaluation \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='Survived', metricName='areaUnderROC')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation with SciKit-Learn\n",
    "If you want to generate other evaluations such as a confusion matrix or a classification report, you could always use the scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.87       116\n",
      "           1       0.86      0.72      0.78        82\n",
      "\n",
      "    accuracy                           0.83       198\n",
      "   macro avg       0.84      0.82      0.82       198\n",
      "weighted avg       0.84      0.83      0.83       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(['Survived']).collect()\n",
    "y_pred = predictions.select(['prediction']).collect()\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+\n",
      "|Survived|prediction|         probability|\n",
      "+--------+----------+--------------------+\n",
      "|       0|       0.0|[0.87805007925591...|\n",
      "|       0|       0.0|[0.52932263083207...|\n",
      "|       1|       1.0|[0.41824239022645...|\n",
      "|       1|       1.0|[0.24887939411156...|\n",
      "|       0|       0.0|[0.67944652654420...|\n",
      "|       1|       0.0|[0.87721640405769...|\n",
      "|       0|       0.0|[0.54062209225734...|\n",
      "|       0|       0.0|[0.59965089522779...|\n",
      "|       0|       0.0|[0.87989037427045...|\n",
      "|       0|       0.0|[0.87805007925591...|\n",
      "|       1|       1.0|[0.17182219123661...|\n",
      "|       1|       1.0|[0.17182219123661...|\n",
      "|       0|       0.0|[0.69766666817993...|\n",
      "|       1|       0.0|[0.70603093171371...|\n",
      "|       0|       0.0|[0.87989037427045...|\n",
      "|       1|       1.0|[0.44194310571070...|\n",
      "|       0|       0.0|[0.87805007925591...|\n",
      "|       1|       1.0|[0.26178465297380...|\n",
      "|       0|       0.0|[0.77291472359105...|\n",
      "|       0|       0.0|[0.87989037427045...|\n",
      "+--------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8554656780137061"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data1 = spark.read.csv('titanic.csv', inferSchema=True, header=True)\n",
    "data1 = data1.withColumn('AgeMissing', f.when(f.isnull(data1['age']), 1).otherwise(0))\n",
    "age_imputer = Imputer(strategy='mean', inputCols=['Age'], outputCols=['AgeImputed'])\n",
    "gender_indexer = StringIndexer(inputCol='Gender', outputCol='GenderIndexed')\n",
    "pclass_encoder = OneHotEncoderEstimator(inputCols=[\"Pclass\"],outputCols=[\"PclassVec\"])\n",
    "assembler = VectorAssembler(inputCols=['SibSp', 'Parch', 'Fare', 'AgeMissing', 'AgeImputed', 'GenderIndexed', 'PclassVec'], outputCol='features')\n",
    "algo = RandomForestClassifier(featuresCol='features', labelCol='Survived')\n",
    "# chain the steps in a piperline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[age_imputer, gender_indexer, pclass_encoder, assembler, algo]) \n",
    "train1, test1 = data1.randomSplit([0.8, 0.2], seed=12345)\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(train1)\n",
    "# Predictions\n",
    "predictions = model.transform(test1)\n",
    "predictions.select(['Survived','prediction', 'probability']).show()\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='Survived', metricName='areaUnderROC')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
